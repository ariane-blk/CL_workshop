---
title: "intro"
author: "Ariane"
date: "2025-07-04"
output: html_document
---

## Why Standardize Amyloid PET Quantification?

Amyloid PET imaging has revolutionized our ability to detect and quantify amyloid-beta plaques *in vivo* â€” a defining pathological characterisic of Alzheimer's disease. But different tracers (e.g., PiB, Florbetapir, Florbetaben, Flutemetamol, [F-18]NAV4694) and processing pipelines produce different scales. A value of 1.4 SUVR in one study might mean something very different in another.

<div style="text-align: center;">
  <img src="images/ref_reg.jpg" style="width:30%;" />
</div>

This variability makes it difficult to:
- Compare results across studies or centres
- Pool data from different cohorts
- Define universally accepted cut-offs for amyloid positivity

To address this, the **Centiloid scale (CL)** was proposed by Klunk et al. (2015), with the idea to define a **standardized metric** across tracers and pipeline. The scale has two *anchor* points:

- **0 CL**: Mean amyloid burden in young healthy controls  
- **100 CL**: Mean amyloid burden in mild-t0-moderate Alzheimer's disease patients

Once mapped to this scale, SUVR values from *any* validated tracer and pipeline can be **converted to Centiloids**, enabling consistent interpretation and comparison in various contexts (see Interpretation tab).

## Key Features of the Centiloid Scale

- ðŸ“ˆ Linear transformation of SUVRs  
- ðŸ“Š Validated across multiple tracers and processing methods  
- ðŸ”§ Requires pipeline validation if using custom methods  
- ðŸ”— Supported by an open-access reference implementation via [GAAIN](https://www.gaain.org/centiloid-project)

## Workshop overview:

This app was design to provide an overview of the Centiloid scale with interactive examples.
The following topics are covered:
- How the Centiloid is defined and calculated  
- How to interpretation it
- How to validate your own processing pipeline  
- Provide a software with Centiloid pipeline database

Letâ€™s get started :)

